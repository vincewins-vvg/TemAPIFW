#
# *******************************************************************************
# * Copyright © Temenos Headquarters SA 2021. All rights reserved.
# *******************************************************************************
#

# Default values for holdingsmsvc.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

namespace: paymentorder
#Name			  : ReplicaCount
#Description      : ReplicaCount is used to specify the number of Pod instances running in a cluster any given time to prevent users from losing access to their application when a Pod fails or is inaccessible.
replicacount:
#Name			  : paymentsapi
#Description      : Specifies the No of replicas for api pods for payments
#Default Value    : 1
  paymentorderapi: 1
#Name			  : paymentsingester
#Description      : Specifies the No of replicas for ingester pods for payments
#Default Value    : 1
  paymentorderingester: 1
#Name			  : schemaregistry
#Description      : Specifies the No of replicas for schema registry
#Default Value    : 1
  schemaregistry: 1
  
#Name             : kafkatopic
#Description      : Kafka topics names are the categories used to organize messages.Each topic has a name that is unique across the entire Kafka cluster.  
kafkatopic:
#Name             : topicpartitions
#Description      : The default number of partitions per topic.
#Default Value    : 3
  topicpartitions: 3
#Name             : retentionms
#Description      : This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the "delete" retention policy. This represents an SLA on how soon consumers must read their data.
#Default Value    : 7200000
  retentionms: 7200000
#Name             : segmentbytes
#Description      : The log for a topic partition is stored as a directory of segment files. This setting controls the size to which a segment file will grow before a new segment is rolled over in the log.
#Default Value    : 1073741824
  segmentbytes: 1073741824
#Name             : replicas
#Description      : Replication is the process of having multiple copies of the data available across different servers for purpose of availability in case one of the brokers goes down. In Kafka, replication happens at the partition level i.e. copies of the partition are maintained at multiple broker instances.When we say a topic has a replication factor of 3, this means we will be having three copies of each of its partitions
#Default Value    : 3
  replicas: 3
#Name			  : avrotopic
#Description      : Specifies the topic which is used to fetch events when it is produced for avro use case.
#Default Value    : table-update-paymentorder
  avrotopic: table-update-paymentorder
#Name	          : outboxtopic
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : paymentorder-outbox
  outboxtopic: paymentorder-outbox
#Name	          : eventstoretopic
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : ms-eventstore-inbox-topic
  eventstoretopic: ms-eventstore-inbox-topic
#Name	          : inboxtopic
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : ms-paymentorder-inbox-topic
  inboxtopic: ms-paymentorder-inbox-topic
#Name	          : eventtopic
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : paymentorder-event-topic
  eventtopic: paymentorder-event-topic
#Name	          : eventtopic
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : error-paymentorder
  errortopic: error-paymentorder
#Name			  : inboxerrortopic
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : ms-paymentorder-inbox-error-topic
  inboxerrortopic: ms-paymentorder-inbox-error-topic
#Name			  : errorstream_producerid
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : ms-paymentorder-ingester-error-producer
  errorstreamproducerid: ms-paymentorder-ingester-error-producer
#Name			  : consumergroupid
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : ms-paymentorder-ingester-consumer
  consumergroupid: ms-paymentorder-ingester-consumer
#Name			  : multiparttopic
#Description      : Specifies the topic which is used to fetch events with message when it is consumed.
#Default Value    : multipart-topic
  multiparttopic: multipart-topic
  

#Name             : image
#Description      : A container image represents binary data that encapsulates an application and all its software dependencies. Images are  pushed to external repositories, this section contains the name of repositories, image and tag 
#Example          : Consider our external repository is "acr.azurecr.io" and tag is "21.0.0". It should be like acr.azurecr.io/temenos/ms-paymentorder-service:21.0.0
image:
#Name             : paymentsapi repository
#Description      : Specifies the name of the api image stored in external repository.Kubernetes pod can pull Docker images directly when a deployment takes place.
#Default Value    : dev.local/temenos/ms-paymentorder-service
  paymentorderapi:
    repository: dev.local/temenos/ms-paymentorder-service
#Name             : tag
#Description      : Specifies the release version of the image
    tag: DEV 
#Name             : pullPolicy
#Description      : When creating the POD, one can specify the imagePullPolicyspecification, which guides the Kubelet service on how to pull the specified image during an update
#Possible Values  : Always--> Kubernetes will always pull the image from the Repository | IfNotPresent --> Kubernetes will only pull the image when it does not already exist on the node | Never--> Kubernetes will never pull the image
    pullPolicy: Never
#Name             : paymentsingester repository
#Description      : Specifies the name of the ingester image stored in external repository.Kubernetes pod can pull Docker images directly when a deployment takes place.
#Default Value    : dev.local/temenos/ms-paymentorder-ingester
  paymentorderingester:
    repository: dev.local/temenos/ms-paymentorder-ingester
#Name             : tag
#Description      : Specifies the release version of the image
    tag: DEV
#Name             : pullPolicy
#Description      : When creating the POD, one can specify the imagePullPolicyspecification, which guides the Kubelet service on how to pull the specified image during an update
#Possible Values  : Always--> Kubernetes will always pull the image from the Repository | IfNotPresent --> Kubernetes will only pull the image when it does not already exist on the node | Never--> Kubernetes will never pull the image
    pullPolicy: Never
#Name             : paymentorderinboxoutbox repository
#Description      : Specifies the name of the inboxoutbox image stored in external repository.Kubernetes pod can pull Docker images directly when a deployment takes place.
#Default Value    : dev.local/temenos/ms-paymentorder-inboxoutbox
  paymentorderinboxoutbox:
    repository: dev.local/temenos/ms-paymentorder-inboxoutbox
#Name             : tag
#Description      : Specifies the release version of the image
    tag: DEV
#Name             : pullPolicy
#Description      : When creating the POD, one can specify the imagePullPolicyspecification, which guides the Kubelet service on how to pull the specified image during an update
#Possible Values  : Always--> Kubernetes will always pull the image from the Repository | IfNotPresent --> Kubernetes will only pull the image when it does not already exist on the node | Never--> Kubernetes will never pull the image
    pullPolicy: Never  
#Name             : schemaregistry repository
#Description      : Specifies the name of the schema-registry image stored in external repository.Kubernetes pod can pull Docker images directly when a deployment takes place.
#Default Value    : confluentinc/cp-schema-registry 
  schemaregistry:
    repository: confluentinc/cp-schema-registry
#Name             : tag
#Description      : Specifies the release version of the image
    tag: 5.3.0
#Name             : pullPolicy
#Description      : When creating the POD, one can specify the imagePullPolicyspecification, which guides the Kubelet service on how to pull the specified image during an update
#Possible Values  : Always--> Kubernetes will always pull the image from the Repository | IfNotPresent --> Kubernetes will only pull the image when it does not already exist on the node | Never--> Kubernetes will never pull the image
    pullPolicy: Never
#Name             : paymentorderscheduler repository
#Description      : Specifies the name of the scheduler image stored in external repository.Kubernetes pod can pull Docker images directly when a deployment takes place.
#Default Value    : dev.local/temenos/ms-paymentorder-scheduler
  paymentorderscheduler:
    repository: dev.local/temenos/ms-paymentorder-scheduler
#Name             : tag
#Description      : Specifies the release version of the image
    tag: DEV
#Name             : pullPolicy
#Description      : When creating the POD, one can specify the imagePullPolicyspecification, which guides the Kubelet service on how to pull the specified image during an update
#Possible Values  : Always--> Kubernetes will always pull the image from the Repository | IfNotPresent --> Kubernetes will only pull the image when it does not already exist on the node | Never--> Kubernetes will never pull the image
    pullPolicy: Never
#Name             : fileingester repository
#Description      : Specifies the name of the fileingester image stored in external repository.Kubernetes pod can pull Docker images directly when a deployment takes place.
#Default Value    : dev.local/temenos/ms-paymentorder-fileingester
  fileingester:
    repository: dev.local/temenos/ms-paymentorder-fileingester
#Name             : tag
#Description      : Specifies the release version of the image
    tag: DEV
#Name             : pullPolicy
#Description      : When creating the POD, one can specify the imagePullPolicyspecification, which guides the Kubelet service on how to pull the specified image during an update
#Possible Values  : Always--> Kubernetes will always pull the image from the Repository | IfNotPresent --> Kubernetes will only pull the image when it does not already exist on the node | Never--> Kubernetes will never pull the image
    pullPolicy: Never     

apideployment: paymentorder-api
schemaregistry: schema-registry
schemaregistrysvc: schema-registry-svc

#Name             : env
#Description      : Environmental variables are specified here
env:
#Name             : database
#Description      : database related parameters values are specified here.
  database:
#Name 			  : database_key
#Description 	  : specify the name of the database server.
#Possible values  : mongodb | postgresql
    DATABASE_KEY: 
#Name			  : MONGODB_DBNAME
#Description	  : Specify the name of the database used in mongodb
    MONGODB_DBNAME: 
# Name			  : MONGODB_CONNECTIONSTR
# Description	  : The general form of the connection URL is
    # The general form of the connection URL is
    #  ex.  oracle:          jdbc:oracle:thin:@<host_or_ip>:1521:<db_name>
    #  ex.  db2:             jdbc:db2://<host_or_ip>:50000/<db_name>
    #  ex.  ms-sql:          jdbc:sqlserver://<host_or_ip>:1433;databaseName=<db_name>
    #  ex.  mongodb:         mongodb://[username:password@]host1[:port1][,...hostN[:portN]][/[defaultauthdb][?options]]
    # The general form of the connection URL for shared cluster is
    # mongodb://<hostname>:<port>,<hostname>:<port>
    # mongodb://mongos0.example.com:27017,mongos1.example.com:27017,mongos2.example.com:27017


    #mongodb:// -- A required prefix to identify that this is a string in the standard connection format.
    
    #host[:port] -- The host (and optional port number) where mongos instance for a sharded cluster is running. You can specify a hostname, IP address, or UNIX domain socket. Specify as many hosts as appropriate for your deployment topology.If the port number is not specified, the default port 27017 is used.
    MONGODB_CONNECTIONSTR: mongodb://mongodb-0.mongodb-svc.mongodb.svc.cluster.local:27017,mongodb-1.mongodb-svc.mongodb.svc.cluster.local:27017,mongodb-2.mongodb-svc.mongodb.svc.cluster.local:27017
#Name			  : MONGO_CRED
#Description	  : A Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key.If MONGO_CRED is set to 'Y'. It will allow to fetch the DB username and DB password through k8s secrets for MySQL DB.
#Possible values  : Y | N	  
#Default value    : N
    MONGO_CRED: "N"
    
    #MONGODB_USER : root
    #MONGODB_PASS : ENC(0jDFL9aa9VbB/KfSH6zfEQ==)
    
     #POSTGRESQL:
#Name			  : POSTGRESQL_CRED
#Description	  : A Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key.If MONGO_CRED is set to 'Y'. It will allow to fetch the DB username and DB password through k8s secrets for MySQL DB.
#Possible values  : Y | N	  
#Default value    : N 
    POSTGRESQL_CRED: "N"
 # Name			  : POSTGRESQL_CONNECTIONURL
# Description	  : The general form of the connection URL is
    #  ex.  oracle:          jdbc:oracle:thin:@<host_or_ip>:1521:<db_name>
    #  ex.  db2:             jdbc:db2://<host_or_ip>:50000/<db_name>
    #  ex.  ms-sql:          jdbc:sqlserver://<host_or_ip>:1433;databaseName=<db_name>
    #  ex.  mongodb:         mongodb://[username:password@]host1[:port1][,...hostN[:portN]][/[defaultauthdb][?options]]
    #  ex.  postgresql       jdbc:postgresql://host:port/database
    #
    #With JDBC, a database is represented by a URL
    # jdbc:postgresql://host:port/database
    # 
    # host -- The host name of the server. Defaults to localhost. To specify an IPv6 address your must enclose the host parameter with square brackets, for example:

    # jdbc:postgresql://[::1]:5740/accounting
    # 
    # port -- The port number the server is listening on. Defaults to the PostgreS

    # database -- The database name.   
    POSTGRESQL_CONNECTIONURL:
#Name             : POSTGRESQL_POOLSIZE    
#Description	  : number of connections maintained in the pool.
#Default Value    : "10"  
    POSTGRESQL_POOLSIZE: "10"
#Name			  : POSTGRESQL_USERNAME
#Description      : To interact with a database, you generally first need to connect to the server. You supply a username (uid) for a server login.
#Default value    : paymentorderusr
    POSTGRESQL_USERNAME: paymentorderusr
#Name			  : POSTGRESQL_PASSWORD
#Description      : To interact with a database, you generally first need to connect to the server. You supply a username (uid) for a server login.
#Default value    : paymentorderpass   
    POSTGRESQL_PASSWORD: paymentorderpass
    
    #For encrypted password,
    #POSTGRESQL_PASSWORD: ENC(0QEqdsmi+qUTOAINlDjzKmLl9TIdoN4g7szv2l2u25Q=)

#Name		      :temn_msf_db_pass_encryption_key,temn_msf_db_pass_encryption_algorithm
#Description      :For encrypting the plain text's, need some inputs i.e., Password and an Algorithm which is used to decrypt an encrypted input.These two values are mandatory to encrypt the plain text.
#Default Value    :temenos, PBEWithMD5AndTripleDES
    temn_msf_db_pass_encryption_key: temenos
    temn_msf_db_pass_encryption_algorithm: PBEWithMD5AndTripleDES    
#Name             :kafka 
#Description      :Kafka is used to build real-time streaming data pipelines and real-time streaming applications. A data pipeline reliably processes and moves data from one system to another, and a streaming application is an application that consumes streams of data      
  kafka:
#Name             :temnmsfstreamvendor
#Description      :It specifies the vendor used to process messages to topic. by default we are using kafka as vendor
#Default Value    :kafka
    temnmsfstreamvendor: kafka
#Name             :temnqueueimpl
#Description      :It specifies the queue used to identify the listener container.(processing messages)
#Default Value    :kafka
    temnqueueimpl: kafka
#Name             : generic_ip
#Description      : specify the ip address value.
    generic_ip: 127.0.0.1
#Name 			  : kafkabootstrapservers
#Descripton       : It contains a list of host/port pairs for establishing the initial connection to the Kafka cluster.A host and port pair uses : as the separator.
#Example		  : localhost:9092,localhost:9092,another.host:9092
#Default Value	  : my-cluster-kafka-bootstrap.kafka:9092
    kafkabootstrapservers: my-cluster-kafka-bootstrap.kafka:9092
#Name 			  : schema_registry_url
#Description	  : Schema Registry is an application that resides outside of your Kafka cluster and handles the distribution of schemas to the producer and consumer by storing a copy of schema in its local cache. Schema registry url is used to connect schema registry in kafka.
#Default Value	  : http://schema-registry-svc.kafka.svc.cluster.local
    schema_registry_url: http://schema-registry-svc.kafka.svc.cluster.local
    kafkaAliases: "N"
# Name			  : kafkaip,kafka0ip,kafka1ip,kafka2ip,devdomain
# Description	  : Set the following variables of kafka ip for hostAliases    
    kafkaip:
    kafka0ip:
    kafka1ip:
    kafka2ip:
    devdomain:
# Name			  : kafkaHostName,kafka0HostName,kafka1HostName,kafka2HostName,devdomainHostName
# Description	  : Set the following variables of kafka hostname for hostAliases     
    kafkaHostName:
    kafka0HostName:
    kafka1HostName:
    kafka2HostName:
    devdomainHostName:
  scheduler:
#Name             : temn_msf_scheduler_nosqlInboxCatchup_cron_trigger_time
#Description      : Frequency to trigger the scheduler job is set in this property .Cron trigger time for sql inbox catchup
#Default value    : 0 */30 * ? * * 
    temn_msf_scheduler_nosqlInboxCatchup_cron_trigger_time: 0 */30 * ? * * 
#Name             : temn_msf_scheduler_nosqlOutboxCatchup_cron_trigger_time
#Description      : Frequency to trigger the scheduler job is set in this property .Cron trigger time for sql outbox catchup 
#Default value    : 0 */30 * ? * *
    temn_msf_scheduler_nosqlOutboxCatchup_cron_trigger_time: 0 */30 * ? * *
#Name             : temn_msf_scheduler_nosqlOutboxCatchup_cron_trigger_time
#Description      : Frequency to trigger the scheduler job is set in this property .Cron trigger time for adapter scheduler
#Default value    : 59 * * ? * *   
    temn_msf_scheduler_adapterscheduler_cron_trigger_time: 59 * * ? * *
#Name             : schedule
#Description      : Specify the Frequency to trigger the scheduler job is set in this property. Default is 5 minutes
#DefaultValue     : "*/5 * * * *" 
    schedule: "*/5 * * * *"    
  schemaregistry:
#Name             : SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS
#Description      : bootstrap. servers is used to coordinate Schema Registry instances (leader election), and store schema data
#Default Value    : PLAINTEXT://my-cluster-kafka-bootstrap.kafka:9092
    SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://my-cluster-kafka-bootstrap.kafka:9092
#Name             : SCHEMA_REGISTRY_HOST_NAME
#Description      : Hostname to publish to ZooKeeper for clients to use
#Default Value    : schema-registry
    SCHEMA_REGISTRY_HOST_NAME: schema-registry

#Name             : SCHEMA_REGISTRY_LISTENERS  
#Description      :listeners that listen for API requests over either HTTP or HTTPS.If multiple listeners are configured, the first listener’s port is used for its identity.
    #Type: list
    #Default: “http://0.0.0.0:8081”
    #Importance: high
    SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
#Name             : SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT  
#Description      :The timeout for initialization of the Kafka store, including creation of the Kafka topic that stores schema data..
#Default Value    : 500
    SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: "500"
#Name             : SCHEMA_REGISTRY_CUB_ZK_TIMEOUT  
#Description      :ZooKeeper session timeout
#Default Value    : 500
    #ZooKeeper session timeout
    SCHEMA_REGISTRY_CUB_ZK_TIMEOUT: "500"
#Name             : SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL  
#Description      : The security protocol to use when connecting with Kafka, the underlying persistent storage.
#Default Value    : PLAINTEXT
#Possible values  : PLAINTEXT | SASL_PLAINTEXT | SSL | SASL_SSL  
    SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
  nosqlinboxcatchupscheduler:
#Name             : temn_msf_scheduler_inboxcleanup_schedule
#Description      : Specifies No of Minutes required to hold the records inside ms_inbox_events table before automatic deletion.
#Default value    : 60  
    temn_msf_scheduler_inboxcleanup_schedule: "60"
#Name             : schedule
#Description      : Specify the Frequency to trigger the scheduler job is set in this property. Default is 5 minutes
#DefaultValue     : 5
    schedule: 5    
#Name             : service
#Description      : A Service in Kubernetes is a REST object, similar to a Pod. Like all of the REST objects, you can POST a Service definition to the API server to create a new instance.#specifies the port ,type  for the eventstore api and ingester service.
service:
  paymentorderapi:
#Name             : type
#Description      : When the Service type is set to LoadBalancer, Kubernetes provides functionality equivalent to type equals ClusterIP to pods within the cluster and extends it by programming the (external to Kubernetes) load balancer with entries for the nodes hosting the relevant Kubernetes pods
#Default Value  :LoadBalancer
    type: LoadBalancer
#Name             : port
#Description      : A port number is a way to identify a specific process to which an internet or other network message is to be forwarded when it arrives at a server for api.
#Default value    :80   
    port: 80
  schemaregistry:
#This is the default service type that exposes the service on a cluster-internal IP by making the service only reachable within the cluster
    type: ClusterIP
 #Name             : port
#Description      : A port number is a way to identify a specific process to which an internet or other network message is to be forwarded when it arrives at a server for api.
#Default value    :80  
    port: 80
#Name           : targetport
#Description    : A Service can map any incoming port to a targetPort. By default and for convenience, the targetPort is set to the same value as the port field.
#Default value  : 8081
    targetport: 8081
  schemaregistrynp:
#Node port is the port on which the service can be accessed from external users using Kube-Proxy.
    type: NodePort
#Name             : port
#Description      : A port number is a way to identify a specific process to which an internet or other network message is to be forwarded when it arrives at a server for api.
#Default value    :8081   
    port: 8081
    nodeport: 32101    
#Name           :ports
#Description    : specifies the port ,name ,protocol,targetport for the eventstore ingester and api service.
ports:
#Name           :name
#Description    :It's a formally defined set of rules for communication between a client (the network resource requesting data or services) and a server (the resource that receives and responds to the request)
#Default value  : http
  name: http
#Name           :port
#Description    : A port number is a way to identify a specific process to which an internet or other network message is to be forwarded when it arrives at a server
#Default value  :8080  
  port: 8080
#Name           : protocol
#Description    : The default protocol for Services is TCP; you can also use any other supported protocol(https://kubernetes.io/docs/concepts/services-networking/service/#protocol-support).
#Default value  : TCP
  protocol: TCP
#Name           : targetport
#Description    : A Service can map any incoming port to a targetPort. By default and for convenience, the targetPort is set to the same value as the port field.
#Default value  : 30020
  targetport: 30020
  
external:
  enabled: true
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  
msf:
#Name           : jms
#Description    :The Java Message Service (JMS) API is a messaging standard that allows application components based on the Java Platform Enterprise Edition (Java EE) to create, send, receive, and read messages. It enables distributed communication that is loosely coupled, reliable, and asynchronous. TCP/IP Listener is a lightweight Adapter Service which servers IS08583 Requests with almost no latency added to the overall flow of ATM requests.
  jms:
#Name           : provider
#Description    : This is the JMS provider URL which runs in JBOSS. The host and the port should be configured here
#Default value  : tcp://10.92.4.94:61616
    provider: tcp://10.92.4.94:61616
#Name           : factory
#Description    : A factory of the ActiveMQ InitialContext which contains ConnectionFactory instances as well as a child context called destinations which contain all of the current active destinations, in child context depending on the QoS such as transient or durable and queue or topic.
#Default value  : org.apache.activemq.jndi.ActiveMQInitialContextFactory   
    factory: org.apache.activemq.jndi.ActiveMQInitialContextFactory
#Name           : vendor
#Description    : specifies the vendor used in jms
#Default value  : activemq
    vendor: activemq

  debulking:
#Name          : retryTime
 #Description   : total retry count before generating output file for debulking usecase
 #Default Value : 100
    retryTime: 100
 #Name          : jobrecordlistsize
 #Description   : no of records to be present in output file
 #Default Value : 10  
    jobrecordlistsize: 10
#Name           :ingest
#Description    :enable/disable raising the cloud event
#Default Value  :true
  ingest:
    cloudevent: true

  scheduler:
    threadexecutor: 8
    kubernetes: true
#Name           :config
#Description    :if the config is set true the service name will set as scheduler
#Default Value  :false
    config: false

  others:
    name: ms-paymentorder
#Name            : execenv
#Description     : specify the execution environment.  
#possible values : server | azure
#Default value   : server
    execenv: server
#Name            : authzenabled
#Description     : Enable/Disable the XACML policy authorization. XACML policy authorization is used to configure security policies and access rights to information for APIs.
#Default Value   : false
    authzenabled: false

inboxoutbox:
  inbox:
#Name        :threadpoolcount
#Description :no of thread count required to process the inbox events.
#Default Value: 2
    threadpoolcount: 2
    namespace: paymentorder-inbox

  outbox:
#Name        :threadpoolcount
#Description :no of thread count required to process the outbox events.
#Default Value: 2
   threadpoolcount: 2
   namespace: paymentorder-outbox   
   
logging:     
#Name           :socketHost
#Description    :Specifies the Logstash exposed host name. To enable logging socketHost should be uncommented.
#  socketHost: "192.168.1.37"
#Name           :socketPort
#Description    :Specifies the Logstash exposed host port. To enable logging socketPort should be uncommented.
#  socketPort: "4560"
#Name           :exportType
#Description    :Specifies the Logstash Log appender type. To enable logging exportType should be uncommented.
#Possible Values:console | socket | routing
  exportType: #"socket"
#Name           :protocol
#Description    : The default protocol for Services is TCP; you can also use any other supported protocol(https://kubernetes.io/docs/concepts/services-networking/service/#protocol-support).
  protocol: #TCP
  
#Name                 : metrics
#Description          : Metrics give us insights into the historical and current state of a system.Data instrumented from microservices are pushed to PushGateway service. Prometheus collects data from PushGateway on a regular interval. Grafana is used to visualize data in UI.    
metrics:
  #exporterPort: 9091 
  #exporterHost: 192.168.228.193
#Name                 :publisherPort
#Description          :Specifies the PushGateway service exposed port .publisherPort should be uncommented and required port should be mentioned.
  #publisherPort: 9091
#Name                 :publisherHost
#Description          :Specifies the PushGateway service exposed hostname .publisherHost should be uncommented and required port should be mentioned.
  #publisherHost: 192.168.228.193
#Name                 :metricsDisabled
#Description          : #To enable metrics monitoring in microservices publisherPort,publisherHost can be configured with pushgateway port and host address. Metrics will be disabled by default. to enable change the value to false
#Default value        : true
#Possible Values      : true | false
  metricsDisabled: "true"
#Name           : tracing
#Description    :Tracing is a way of profiling and monitoring events in applications. With the right information, a trace can reveal the performance of critical operations. It can also help to a breakdown of our operations to our database, APIs, or other microservices.    
tracing:
#Name           : enabled
#Description    : To enable Tracing. it should be changed to true.
#Possible Values:true | false
#Default Value  : false
  enabled: false
#Name           : port
#Description    : Port number of tracer backend service.
  # port: 14268
#Name           : host
#Description    : Host of any tracer backend service (Currently we are using Jaeger)
  # host: 192.168.0.199
  
pit:
# Name : Jwt_Token_Issuer
# Description : Identifies the issuer of the authentication token.
  JWT_TOKEN_ISSUER:
# Name : Jwt_Token_Principal_Claim
# Description : Indicates the claim in which the user principal is provided.
  JWT_TOKEN_PRINCIPAL_CLAIM:
# Name : Id_Token_Signed
# Description : Enables the JWT signature validation along with the header and payload
  ID_TOKEN_SIGNED:
# Name : Jwt_Token_Public_Key
# Description : Indicates Base64 encoded public key content that can be directly loaded as a public key certificate.
  JWT_TOKEN_PUBLIC_KEY:
# Name : Jwt_Token_Public_Key_Cert_Encoded
# Description : Indicates Base64 encoded public key content that can be directly loaded as a public key certificate.
  JWT_TOKEN_PUBLIC_KEY_CERT_ENCODED:   

# Name			: imagePullSecrets
# Description	: Docker registry secret contains the Oracle Cloud Infrastructure credentials to use when pulling the image. You have to specify the image to pull from Container Registry, including the repository location and the Docker registry secret to use, in the application's manifest file. To build docker registry secret,kindly use kubectl create secret docker-registry <secret-name> --docker-server=<region-key>.ocir.io --docker-username='<tenancy-namespace>/<oci-username>' --docker-password='<oci-auth-token>' --docker-email='<email-address>'. Refer https://docs.oracle.com/en-us/iaas/Content/Registry/Tasks/registrypullingimagesfromocir.htm#:~:text=To%20create%20a%20Docker%20registry%20secret%3A. imagePullSecrets Specifies the <secret-name> is a name of your choice, that you will use in the manifest file to refer to the secret.
imagePullSecrets: